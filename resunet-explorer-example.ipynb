{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdCkyK1SZmKq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download dataset and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "PLDAEJzlFedp"
   },
   "source": [
    "## Google Colab import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33917,
     "status": "ok",
     "timestamp": 1650593765466,
     "user": {
      "displayName": "Wesley Nogueira Galvão",
      "userId": "13330399802249856427"
     },
     "user_tz": 180
    },
    "id": "YZVoNJml_DZA",
    "outputId": "ffb0746a-09dc-4b7b-cdc8-35cb14319080",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9JyBsGEYK-F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "!gdown --id 1RhJmQ2eBo7KYoXpCQ3mn2A02YUrFo4ID\n",
    "# Download torchtrainer library\n",
    "!gdown --id 1DzSFLvGsyxmx2j1N-l5k0P_4Bx2i5g7D\n",
    "# Download learner vessel\n",
    "!gdown --id 1EP93TNX180IGYefQnVaeL4YeXVtZYjjb"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Copy torchtrainer library\n",
    "!cp '/content/drive/MyDrive/Iniciação Científica/Wesley Galvão.lnk/Notebooks/torchtrainer' -r '/content/'\n",
    "# Copy model checkpoint \n",
    "!cp '/content/drive/MyDrive/Iniciação Científica/Wesley Galvão.lnk/Modelos/learner_vessel.tar' '/content/'\n",
    "# Copy image dataset\n",
    "!cp '/content/drive/MyDrive/Iniciação Científica/Wesley Galvão.lnk/Notebooks/Dados/data' -r '/content'"
   ],
   "metadata": {
    "id": "ZmHXifUDII-8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSyLNtWSZjte",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A1XhXaTYw3IR",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650593802266,
     "user_tz": 180,
     "elapsed": 10411,
     "user": {
      "displayName": "Wesley Nogueira Galvão",
      "userId": "13330399802249856427"
     }
    },
    "outputId": "d9553716-192a-4ff3-f68c-06e128cfe8ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyprog\r\n",
      "  Downloading pyprog-1.1.0.post2-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: pyprog\r\n",
      "Successfully installed pyprog-1.1.0.post2\r\n",
      "Collecting imgaug==0.4\r\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 948 kB 5.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting matplotlib\r\n",
      "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 11.2 MB 10.7 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting opencv-python\r\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 60.5 MB 29.9 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: six in /home/wesleygalvao/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages (from imgaug==0.4) (1.16.0)\r\n",
      "Collecting imageio\r\n",
      "  Downloading imageio-2.18.0-py3-none-any.whl (3.4 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 3.4 MB 21.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting scipy\r\n",
      "  Downloading scipy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 42.1 MB 28.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting Shapely\r\n",
      "  Downloading Shapely-1.8.1.post1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.0 MB 29.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting scikit-image>=0.14.2\r\n",
      "  Downloading scikit_image-0.19.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 14.0 MB 16.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting Pillow\r\n",
      "  Downloading Pillow-9.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 4.3 MB 39.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.15 in /home/wesleygalvao/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages (from imgaug==0.4) (1.22.3)\r\n",
      "Collecting PyWavelets>=1.1.1\r\n",
      "  Downloading PyWavelets-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 6.9 MB 29.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /home/wesleygalvao/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages (from scikit-image>=0.14.2->imgaug==0.4) (21.3)\r\n",
      "Collecting tifffile>=2019.7.26\r\n",
      "  Downloading tifffile-2022.4.22-py3-none-any.whl (191 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 191 kB 19.7 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting networkx>=2.2\r\n",
      "  Downloading networkx-2.8-py3-none-any.whl (2.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.0 MB 36.6 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/wesleygalvao/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.14.2->imgaug==0.4) (3.0.8)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/wesleygalvao/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages (from matplotlib->imgaug==0.4) (2.8.2)\r\n",
      "Collecting fonttools>=4.22.0\r\n",
      "  Downloading fonttools-4.33.2-py3-none-any.whl (930 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 930 kB 31.9 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting kiwisolver>=1.0.1\r\n",
      "  Downloading kiwisolver-1.4.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 35.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting cycler>=0.10\r\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\r\n",
      "Installing collected packages: Pillow, tifffile, scipy, PyWavelets, networkx, kiwisolver, imageio, fonttools, cycler, Shapely, scikit-image, opencv-python, matplotlib, imgaug\r\n",
      "Successfully installed Pillow-9.1.0 PyWavelets-1.3.0 Shapely-1.8.1.post1 cycler-0.11.0 fonttools-4.33.2 imageio-2.18.0 imgaug-0.4.0 kiwisolver-1.4.2 matplotlib-3.5.1 networkx-2.8 opencv-python-4.5.5.64 scikit-image-0.19.2 scipy-1.8.0 tifffile-2022.4.22\r\n"
     ]
    }
   ],
   "source": [
    "# Progress bar\n",
    "! pip install pyprog\n",
    "# Install imgaug\n",
    "!pip install imgaug==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6bed8efe",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650593813868,
     "user_tz": 180,
     "elapsed": 11620,
     "user": {
      "displayName": "Wesley Nogueira Galvão",
      "userId": "13330399802249856427"
     }
    },
    "outputId": "e6b96145-9790-45ff-d2cf-29f55ffc6328"
   },
   "outputs": [],
   "source": [
    "import pyprog\n",
    "\n",
    "# Initial imports and device setting\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import interpolate \n",
    "from torch.functional import F\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Libraries for graph\n",
    "import networkx.drawing as draw\n",
    "import networkx as nx\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from torchtrainer.imagedataset import ImageSegmentationDataset\n",
    "from torchtrainer import img_util\n",
    "from torchtrainer import transforms\n",
    "from torchtrainer.models.resunet import ResUNet\n",
    "from torchtrainer.module_util import ActivationSampler\n",
    "\n",
    "# Resunet Explorator library\n",
    "from resunetexplorer.layer_extractor import ExtractResUNetLayers\n",
    "from resunetexplorer.maps_extractor import ExtractResUNetMaps\n",
    "\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "# PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "use_cuda = False\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dev_info = torch.cuda.get_device_properties(device)\n",
    "    print(dev_info)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXoS1pAmbJVZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6smclHNFbVcg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_creation(root_dir_, img_dir_, label_dir_):\n",
    "  \"\"\"\n",
    "  Load the dataset given the complet path.\n",
    "  \"\"\"\n",
    "  # Dataset creation\n",
    "  def img_name_to_label(filename):\n",
    "      return filename.split('.')[0] + '.png'\n",
    "\n",
    "  root_dir = Path(root_dir_)\n",
    "  img_dir = root_dir/img_dir_\n",
    "  label_dir = root_dir/label_dir_\n",
    "\n",
    "  # Data transformations\n",
    "  imgaug_seq = iaa.Sequential([\n",
    "      iaa.CLAHE(clip_limit=6, tile_grid_size_px=12)\n",
    "  ])    \n",
    "  imgaug_seq = transforms.translate_imagaug_seq(imgaug_seq)\n",
    "  valid_transforms = [transforms.TransfToImgaug(), imgaug_seq, transforms.TransfToTensor(), \n",
    "                      transforms.TransfWhitten(67.576, 37.556)]\n",
    "\n",
    "  img_opener = partial(img_util.pil_img_opener, channel=None)\n",
    "  label_opener = partial(img_util.pil_img_opener, is_label=True)\n",
    "  dataset = ImageSegmentationDataset(img_dir, label_dir, name_to_label_map=img_name_to_label, img_opener=img_opener, \n",
    "                                    label_opener=label_opener, transforms=valid_transforms)\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-7wLMdaarzC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_checkpoint(path, device):\n",
    "  \"\"\"\n",
    "  Load the model from a checkpoint given a path to file and the device which \n",
    "  will process the model\n",
    "  \"\"\"\n",
    "  checkpoint = torch.load(path, map_location=torch.device(device))\n",
    "  model = ResUNet(num_channels=1, num_classes=2) \n",
    "  model.load_state_dict(checkpoint['model_state'])\n",
    "  model.eval()\n",
    "  model.to(device);\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJm-UobByQke",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Big Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rig_FWqp7q1J",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def big_matrix(nmaps, layer, img_idx):\n",
    "  \"\"\" \"\"\"\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer)\n",
    "\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[img_idx]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  layer_activation = sampler().detach().to('cpu')[0]\n",
    "\n",
    "  # Get flatten image size\n",
    "  tensor_size = len(torch.flatten(layer_activation[0]))\n",
    "  # Create an empty tensor matrix \n",
    "  big_matrix = torch.empty(size=(nmaps, tensor_size))\n",
    "  # Reshape the layer_activation to build the big_matrix of size nmaps X tensor_size\n",
    "  big_matrix = layer_activation.reshape(nmaps, -1)\n",
    "\n",
    "  \"\"\"\n",
    "  Alternative using for loop\n",
    "\n",
    "  # Stack all flattened images to build a matrix of size nmaps X tensor_size\n",
    "  for i in range(nmaps):\n",
    "    big_matrix[i] = torch.flatten(layer_activation[i])\n",
    "  \"\"\"\n",
    "  \n",
    "  return big_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JaT9nB323pns",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def big_matrix_masked(nmaps, layer, img_idx):\n",
    "  \"\"\" Big matrix for masked feature maps\"\"\"\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer)\n",
    "\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[img_idx]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  layer_activation = sampler().detach().to('cpu')[0]\n",
    "\n",
    "  # apply dilation on label with iteration level = 7\n",
    "  dilated_label = scipy.ndimage.binary_dilation(label, iterations = 7)\n",
    "\n",
    "  # Mask all feature maps of layer_activation\n",
    "  layer_activation_masked = layer_activation*dilated_label\n",
    "\n",
    "  # Get flatten image size\n",
    "  tensor_size = len(torch.flatten(layer_activation_masked[0]))\n",
    "  # Create an empty tensor matrix \n",
    "  big_matrix = torch.empty(size=(nmaps, tensor_size))\n",
    "  # Reshape the layer_activation to build the big_matrix of size nmaps X tensor_size\n",
    "  big_matrix = layer_activation_masked.reshape(nmaps, -1)\n",
    "\n",
    "  \"\"\"\n",
    "  Alternative using for loop\n",
    "\n",
    "  # Stack all flattened images to build a matrix of size nmaps X tensor_size\n",
    "  for i in range(nmaps):\n",
    "    big_matrix[i] = torch.flatten(layer_activation[i])\n",
    "  \"\"\"\n",
    "  \n",
    "  return big_matrix, layer_activation_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dF-hKFZwZqPn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def big_matrix_stats(dataset, layer, nmaps, path):\n",
    "\n",
    "  \"\"\" \"\"\"\n",
    "\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer)\n",
    "\n",
    "  # Apply network to image with index = 0\n",
    "  img, _ = dataset[0]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  layer_activation = sampler().detach().to('cpu')[0]\n",
    "\n",
    "  # Get dataset len\n",
    "  dataset_len = len(dataset)\n",
    "  #dataset_len = 4\n",
    "\n",
    "  #----------- Average ------------------\n",
    "  # Create a matrix numpy array. Size nmaps X nmaps\n",
    "  corr_matrix = np.empty(shape=[nmaps, nmaps])\n",
    "  # Create an empty numpy array\n",
    "  corr_sum = np.zeros([nmaps, nmaps])\n",
    "  # Get flatten image size\n",
    "  tensor_size = len(torch.flatten(layer_activation[0]))\n",
    "  # Create two empty tensors \n",
    "  matrix = torch.zeros([nmaps, tensor_size])\n",
    "  matrix_sum = torch.zeros([nmaps, tensor_size])\n",
    "\n",
    "  # Create Object to progress bar\n",
    "  prog = pyprog.ProgressBar(\" \", \"\", dataset_len)\n",
    "  # Print Task name\n",
    "  print('Computing average of Big Matrix and Correlation Matrix: \\n')\n",
    "  # Update Progress Bar\n",
    "  prog.update()\n",
    "\n",
    "  for idx in range(dataset_len):\n",
    "    # Get the big_matrix\n",
    "    matrix = big_matrix(nmaps, layer, idx)\n",
    "    # Sum of all matrices\n",
    "    matrix_sum = matrix_sum + matrix\n",
    "    # Pearson Correlation\n",
    "    corr_matrix = np.abs(np.corrcoef(matrix))\n",
    "    # Sum of all correlation matrices\n",
    "    corr_sum =  corr_sum + corr_matrix\n",
    "    # Get filename of current image  \n",
    "    filename = dataset.img_file_paths[idx].stem\n",
    "    # Save current Correlation Matrix as a figure\n",
    "    #plot_corr_matrix(path, filename, corr_matrix)\n",
    "\n",
    "    # Set current status\n",
    "    prog.set_stat(idx + 1)\n",
    "    # Update Progress bar again\n",
    "    prog.update()  \n",
    "  \n",
    "  # Make the Progress Bar final\n",
    "  prog.end()\n",
    "\n",
    "  # Compute big matrix average  \n",
    "  matrix_avg = matrix_sum/dataset_len\n",
    "  # Compute big matrix correlation average\n",
    "  corr_avg = corr_sum/dataset_len\n",
    "\n",
    "  #----------- Standard deviation------------------\n",
    "\n",
    "  # Create two empty tensors \n",
    "  matrix = torch.zeros([nmaps, tensor_size])\n",
    "  matrix_std = torch.zeros([nmaps, tensor_size])\n",
    "\n",
    "  # Create an empty numpy array\n",
    "  corr_std = np.zeros([nmaps, nmaps])\n",
    "  corr = np.zeros([nmaps, nmaps])\n",
    "\n",
    "  # Create Object to progress bar\n",
    "  prog = pyprog.ProgressBar(\" \", \"\", dataset_len)\n",
    "  # Print Task name\n",
    "  print('Computing standard deviation of Big Matrix and Correlation Matrix: \\n')\n",
    "  # Update Progress Bar\n",
    "  prog.update()\n",
    "\n",
    "\n",
    "  for idx in range(dataset_len):\n",
    "    # Get the big_matrix\n",
    "    matrix = big_matrix(nmaps, layer, idx)\n",
    "    # Compute the sum part of standard deviation of big matrix\n",
    "    matrix_std = matrix_std + torch.float_power((matrix - matrix_avg),2)\n",
    "    # Pearson Correlation of big_matrix\n",
    "    corr_matrix = np.abs(np.corrcoef(matrix))\n",
    "    # Compute the sum part of standard deviation of correlation matrix\n",
    "    corr_std = corr_std + np.float_power((corr_matrix - corr_avg),2)\n",
    "    # Set current status\n",
    "    prog.set_stat(idx + 1)\n",
    "    # Update Progress bar again\n",
    "    prog.update()\n",
    "    \n",
    "    #print('Desvio padrão: \\n')\n",
    "    #print(idx, matrix_sum.max(), corr_sum.max())\n",
    "\n",
    "  # Make the Progress Bar final\n",
    "  prog.end()\n",
    "\n",
    "  # Compute standard deviation for both big matrix and correlation map\n",
    "  corr_std = np.sqrt(corr_std/(dataset_len-1))\n",
    "  matrix_std = torch.sqrt(matrix_std/(dataset_len-1))\n",
    "\n",
    "  return matrix_avg, matrix_std, corr_avg, corr_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBpe5BDoyXJq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DqaQ_HMTDSud",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pca(n, matrix):\n",
    "  # Set 2 principals components\n",
    "  pca = PCA(n_components=2, whiten=True)\n",
    "\n",
    "  # Transform big_matrix to PCA\n",
    "  principalComponents = pca.fit_transform(matrix)\n",
    "\n",
    "  # Transform to dataframe\n",
    "  pca_df = pd.DataFrame(data = principalComponents\n",
    "              , columns = ['principal_component_1', 'principal_component_2'])\n",
    "  \n",
    "  print(pca_df.head())\n",
    "\n",
    "  # Plot PCA scatter plot\n",
    "  fig = plt.figure(figsize = (8,8))\n",
    "  fig.suptitle('Scartter plot of PCA')\n",
    "  ax = sns.scatterplot(data = pca_df, x = 'principal_component_1', \n",
    "                y ='principal_component_2' )\n",
    "  return pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvQNQrQayZQb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plot Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GVU3AmhERFed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_corr_matrix(path, filename, corr_matrix):\n",
    "  \"\"\" \"\"\"\n",
    "  # Convert to Dataframe\n",
    "  corr_df = pd.DataFrame(corr_matrix)\n",
    "  # Set figure size\n",
    "  fig = plt.figure(figsize=[150, 150])\n",
    "  # Set figure title\n",
    "  plt.title(filename+'-Activation_Maps_Correlation_encoder.resblock1',  fontsize=30)\n",
    "  # Plot a matrix heatmap\n",
    "  sns.heatmap(corr_df, cmap='coolwarm', annot = False)\n",
    "  sns.set(font_scale = 2)\n",
    "  # save the figure\n",
    "  plt.savefig(path+filename+'-Activation_Maps_Correlation_encoder.resblock_mid.jpg', dpi=100, bbox_inches='tight')\n",
    "  # Close figure\n",
    "  plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owShmQwRypCb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Feature Maps Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GSTGV9BIyosr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_interp(layer, mode_ = 'linear', scale_factor_ = 2):\n",
    "  \"\"\"Feature maps interpolation\"\"\"\n",
    "\n",
    "  if mode_ == 'linear':\n",
    "    # Run interpolation on feature maps with chosen scale factor\n",
    "    feature_maps_interpolated = F.interpolate(layer, \n",
    "                                              scale_factor=scale_factor_, \n",
    "                                              mode = mode_)\n",
    "    \n",
    "    feature_maps_interpolated = feature_maps_interpolated.permute(0, 2, 1)\n",
    "\n",
    "    feature_maps_interpolated = F.interpolate(feature_maps_interpolated, \n",
    "                                              scale_factor=scale_factor_, \n",
    "                                              mode = mode_)\n",
    "    \n",
    "    feature_maps_interpolated = feature_maps_interpolated.permute(0, 2 , 1)\n",
    "  \n",
    "    \n",
    "  if mode_ == 'bicubic':\n",
    "    # Change tensor dimension to [batch_size == 1, channels, height, width]\n",
    "    layer = layer[None]\n",
    "    # Run interpolation on feature maps with chosen scale factor\n",
    "    feature_maps_interpolated = F.interpolate(layer, \n",
    "                                              scale_factor=scale_factor_, \n",
    "                                              mode = mode_)\n",
    "    feature_maps_interpolated = torch.squeeze(feature_maps_interpolated)\n",
    "\n",
    "  return feature_maps_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q4gcQp18qHhk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_interp2(layer, img_idx, scale_factor_):\n",
    "  \"\"\"\"\"\"\n",
    "\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer)\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[img_idx]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  feature_maps_interpolated = sampler().detach().to('cpu')[0]\n",
    "\n",
    "  # Run interpolation on feature maps with chosen scale factor\n",
    "  feature_maps_interpolated = F.interpolate(feature_maps_interpolated, \n",
    "                                            scale_factor=scale_factor_, \n",
    "                                            mode = 'linear')\n",
    "  \n",
    "  feature_maps_interpolated = feature_maps_interpolated.permute(0, 2, 1)\n",
    "\n",
    "  feature_maps_interpolated = F.interpolate(feature_maps_interpolated, \n",
    "                                            scale_factor=scale_factor_, \n",
    "                                            mode = 'linear')\n",
    "  \n",
    "  feature_maps_interpolated = feature_maps_interpolated.permute(0, 2, 1)\n",
    "\n",
    "  return feature_maps_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tp0n1IOvLKyw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_interp3(layer, img_idx, zoom_):\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer1)\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[3]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  feature_maps = sampler().detach().to('cpu')[0]\n",
    "  feature_maps_interpolated = ndimage.zoom(feature_maps, zoom_)\n",
    "\n",
    "  return feature_maps_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UtF6_E4IK71Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_sampling(layer, img_idx, kernel_size_):\n",
    "\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer1)\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[3]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  feature_maps = sampler().detach().to('cpu')[0]\n",
    "  # Change tensor dimension to [batch_size == 1, channels, height, width]\n",
    "  feature_maps_sampled = feature_maps[None]\n",
    "  # Run interpolation on feature maps with chosen scale factor\n",
    "  feature_maps_sampled = torch.nn.functional.avg_pool2d(feature_maps_sampled, \n",
    "                                            kernel_size = kernel_size_)\n",
    "\n",
    "  return feature_maps_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gvM4RuYCRUn-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_sampling2(layer, img_idx, kernel_size_):\n",
    "\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer1)\n",
    "  # Apply network to image with index = img_idx\n",
    "  img, _ = dataset[3]\n",
    "\n",
    "  with torch.no_grad():\n",
    "    img = img.to(device)[None]\n",
    "    model(img);\n",
    "\n",
    "  # Get activation maps images for specified layer\n",
    "  feature_maps = sampler().detach().to('cpu')[0]\n",
    "  # Change tensor dimension to [batch_size == 1, channels, height, width]\n",
    "  feature_maps_sampled = feature_maps[None]\n",
    "  # Run interpolation on feature maps with chosen scale factor\n",
    "  feature_maps_sampled = torch.nn.functional.max_pool2d(feature_maps_sampled, \n",
    "                                            kernel_size = kernel_size_)\n",
    "\n",
    "  return feature_maps_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kGB3H2eygjn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tOU3LHj3bcbA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph(corr_matrix, threshold):\n",
    "    \"\"\"Create graph from a correlation matrix\"\"\"\n",
    "    \n",
    "    # Keep correlations larger than threshold\n",
    "    adjacency_mat = np.abs(corr_matrix)>=threshold\n",
    "    \n",
    "    adjacency_mat[np.diag_indices_from(adjacency_mat)] = 0\n",
    "    edges_indices = np.nonzero(adjacency_mat)\n",
    "    graph = nx.Graph(adjacency_mat*corr_matrix)\n",
    "    \n",
    "    correlations = corr_matrix[edges_indices]\n",
    "    edges = list(zip(*edges_indices))\n",
    "    weight = dict(zip(edges, correlations))\n",
    "    nx.set_edge_attributes(graph, weight, 'weight')\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def show_graph(graph, ax=None):\n",
    "    \"\"\"Show graph\"\"\"\n",
    "    \n",
    "    weights = nx.get_edge_attributes(graph, 'weight')\n",
    "    edge_labels = {k:f'{v:.2f}' for k, v in weights.items()}\n",
    "\n",
    "    pos = draw.fruchterman_reingold_layout(graph, weight=None)\n",
    "    nodes_names = {idx:idx for idx in range(0, len(graph))}\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=[25, 25])\n",
    "        ax = fig.add_subplot(111)\n",
    "    draw.draw_networkx_edges(graph, pos, width=1.0, edge_color='k', ax=ax)\n",
    "    draw.draw_networkx_nodes(graph, pos, node_size=200, node_color='C0', ax=ax)\n",
    "    draw.draw_networkx_labels(graph, pos, labels=nodes_names, font_size=8, ax=ax)\n",
    "    draw.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels, label_pos=0.5, font_size=8, rotate=True, ax=ax)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yiEQsWtf83Z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L21UuPvOHTIi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Show activation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YP7xmPMVHRyC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_activation_maps(dataset, layer, out_channels, img_idx):\n",
    "  # Sample the activations on one of the layers\n",
    "  sampler = ActivationSampler(layer)\n",
    "\n",
    "  img, _ = dataset[img_idx]\n",
    "  filename = dataset.img_file_paths[img_idx].stem\n",
    "\n",
    "  with torch.no_grad():\n",
    "      img = img.to(device)[None]\n",
    "      model(img);\n",
    "      \n",
    "  layer_activation = sampler().to('cpu')[0]\n",
    "  plt.figure(figsize=[50, 50])\n",
    "\n",
    "  nrows = out_channels/4\n",
    "  ncols = 16\n",
    "\n",
    "  with PdfPages(r'Feature_maps_resblock1_'+filename+'.pdf') as export_pdf:\n",
    "    for idx in range(out_channels):\n",
    "        fig = plt.subplot(8, 8, idx+1)\n",
    "        # displaying the title\n",
    "        plt.title(idx, fontsize=20)\n",
    "        ax = plt.imshow(layer_activation[idx], 'gray')\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.03, hspace=0.03)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    export_pdf.savefig(dpi=250, orientation='portrait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gnTG2-9Lf6ek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aHhHb5NxaH9c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_correlated_maps_pairs(df_corr, col_1, col_2, fm_layer1, fm_layer2):\n",
    "  \"\"\"\n",
    "  Function to print a set of correlated feature maps from different layers. \n",
    "  The print is pair by pair with the respective correlation level. \n",
    "\n",
    "  - df_corr : dataframe that contains a set of indexes of correlated feature maps from different layers and the correlation level. \n",
    "  - col_1 : Name of the first column of df_corr\n",
    "  - col_2 : Name of the second column of df_corr\n",
    "  - Name of the first column of df_corr\n",
    "  - fm_layer1: A tensor of feature maps. Must be the same set of feature maps realated to col_1\n",
    "  - fm_layer2: A tensor of feature maps. Must be the same set of feature maps realated to col_2\n",
    "  \"\"\"\n",
    "  nrows = df_corr.shape[0]\n",
    "\n",
    "  for row in range(nrows):  \n",
    "    fig = plt.figure(figsize=[11, 13])\n",
    "\n",
    "    idx = 1\n",
    "    fig = plt.subplot(2, 2, idx)\n",
    "    # Get correlation value\n",
    "    corr_value = round(df_corr['correlation'].iloc[row], 2)\n",
    "    # Get layer_activation\n",
    "    idx1 = df_corr[col_1].iloc[row]\n",
    "    # displaying the title\n",
    "    plt.title(f'Masked feature map {col_1} - {str(idx1)} corr: {str(corr_value)}', fontsize = 8)\n",
    "    # Plot figure\n",
    "    ax = plt.imshow(layer1_masked[idx1], 'gray')\n",
    "    # Hide axis\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.03, hspace=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig = plt.subplot(2, 2, idx+1)\n",
    "    # Get layer_activation\n",
    "    idx2 = df_corr[col_2].iloc[row]\n",
    "    # displaying the title\n",
    "    plt.title(f'Masked feature map {col_2} - {str(idx2)} corr: {str(corr_value)}', fontsize = 8)\n",
    "    # Plot figure    \n",
    "    ax = plt.imshow(layer2_masked[idx2], 'gray')\n",
    "    # Hide axis\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.03, hspace=0)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIAmTpNkfE_A",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Similarity_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iGOhd-hl2Nu5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_evaluation(feature_map1, feature_map2, feature_map1_name, feature_map2_name, df_results):\n",
    "  # Euclidian distance\n",
    "  ed_fm1_fm2 = torch.sqrt(torch.sum((feature_map1-feature_map2)**2))\n",
    "\n",
    "  # Flattening  \n",
    "  feature_map1_1d = feature_map1.flatten()\n",
    "  feature_map2_1d = feature_map2.flatten()\n",
    "\n",
    "  # Cossine Distance\n",
    "  cos = nn.CosineSimilarity(dim = 0, eps=1e-6)\n",
    "  cos_fm1_fm2 = cos(feature_map1_1d, feature_map2_1d)\n",
    "\n",
    "  results_dict = {\n",
    "      \"feature_map_1_id\" : feature_map1_name, \n",
    "      \"feature_map_2_id\" : feature_map2_name,\n",
    "      \"euclidian distance\" : ed_fm1_fm2.numpy(), \n",
    "      \"cossine distance\" : cos_fm1_fm2.numpy()\n",
    "  }\n",
    "\n",
    "  df_result = pd.DataFrame([results_dict])\n",
    "  df_results = pd.concat([df_results, df_result])\n",
    "\n",
    "  return df_result , df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SBxM2FORNPT7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# based on:  https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/\n",
    "\n",
    "def image_normalize(img_tensor):\n",
    "  mean, std = img_tensor.mean(), img_tensor.std()\n",
    "\n",
    "  transform_norm = transforms.Compose([\n",
    "      transforms.ToTensor(), \n",
    "      transforms.Normalize(mean, std)                            \n",
    "  ])\n",
    "  # Convert tensor to np\n",
    "  img_np = np.array(img_tensor)\n",
    "  # Get normalized image\n",
    "  img_normalized = transform_norm(img_np)\n",
    "  # Remove batch dimension\n",
    "  img_normalized_squeezed = torch.squeeze(img_normalized)\n",
    "  # Return normalized image\n",
    "  return img_normalized_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YKhfbTQN-7Rt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def similarity(feature_map1, feature_map2):\n",
    "  # Euclidian distance\n",
    "  ed_fm1_fm2 = torch.sqrt(torch.sum((feature_map1-feature_map2)**2))\n",
    "\n",
    "  # Flattening  \n",
    "  feature_map1_1d = feature_map1.flatten()\n",
    "  feature_map2_1d = feature_map2.flatten()\n",
    "\n",
    "  # Cossine Distance\n",
    "  cos = nn.CosineSimilarity(dim = 0, eps=1e-6)\n",
    "  cos_fm1_fm2 = cos(feature_map1_1d, feature_map2_1d)\n",
    "  \n",
    "  return ed_fm1_fm2, cos_fm1_fm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "unldGzPo_L8F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_metrics_normalized(corr_matrix_reduced, layer):\n",
    "\n",
    "  # Create the dataframe to store euclidian and cossine distance \n",
    "  similarity_metrics = pd.DataFrame(columns=(\"feature_map_1_id\", \"feature_map_2_id\", \"euclidian_distance\", \"cossine_distance\"))\n",
    "  # Get number of rows of correlation matrix\n",
    "  nrows = corr_matrix_reduced.shape[0]\n",
    "\n",
    "  # Iterate over the correlation matrix to get the correlated pairs and calculate both euclidian and cossine distance\n",
    "  for i in range(nrows):\n",
    "\n",
    "    # Get feature maps IDs of correlated pairs\n",
    "    feature_map_1_id = corr_matrix_reduced['feature_map_1_id'].loc[i]\n",
    "    feature_map_2_id = corr_matrix_reduced['feature_map_2_id'].loc[i]\n",
    "\n",
    "    # Normalize the feature maps\n",
    "    normalized_fm_1 = image_normalize(layer[feature_map_1_id])\n",
    "    normalized_fm_2 = image_normalize(layer[feature_map_2_id])\n",
    "\n",
    "    # Compute Euclidian distance\n",
    "    ed_fm1_fm2 = torch.sqrt(torch.sum((normalized_fm_1-normalized_fm_2)**2))\n",
    "\n",
    "    # Flattening  \n",
    "    normalized_fm_1 = normalized_fm_1.flatten()\n",
    "    normalized_fm_2 = normalized_fm_2.flatten()\n",
    "\n",
    "    # Compute Cossine Distance\n",
    "    cos = nn.CosineSimilarity(dim = 0, eps=1e-6)\n",
    "    cos_fm1_fm2 = cos(normalized_fm_1, normalized_fm_2)\n",
    "    \n",
    "    # A dictionary to store the data\n",
    "    results_dict = {\n",
    "        \"feature_map_1_id\" : feature_map_1_id, \n",
    "        \"feature_map_2_id\" : feature_map_2_id,\n",
    "        \"euclidian_distance\" : ed_fm1_fm2.numpy(), \n",
    "        \"cossine_distance\" : cos_fm1_fm2.numpy()\n",
    "    }\n",
    "\n",
    "    # Convert the dict to dataframe\n",
    "    df_result = pd.DataFrame([results_dict])\n",
    "    # Concact df_result with similarity_metrics to append new row\n",
    "    similarity_metrics = pd.concat([similarity_metrics, df_result])\n",
    "\n",
    "  # Reset indexes\n",
    "  similarity_metrics.reset_index(drop = True, inplace = True)\n",
    "\n",
    "  return similarity_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "h3XMzjaqQ9_H",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_metrics_unormalized(corr_matrix_reduced, layer):\n",
    "\n",
    "  # Create the dataframe to store euclidian and cossine distance \n",
    "  similarity_metrics = pd.DataFrame(columns=(\"feature_map_1_id\", \"feature_map_2_id\", \"euclidian_distance\", \"cossine_distance\"))\n",
    "  # Get number of rows of correlation matrix\n",
    "  nrows = corr_matrix_reduced.shape[0]\n",
    "\n",
    "  # Iterate over the correlation matrix to get the correlated pairs and calculate both euclidian and cossine distance\n",
    "  for i in range(nrows):\n",
    "\n",
    "    # Get feature maps IDs of correlated pairs\n",
    "    feature_map_1_id = corr_matrix_reduced['feature_map_1_id'].loc[i]\n",
    "    feature_map_2_id = corr_matrix_reduced['feature_map_2_id'].loc[i]\n",
    "\n",
    "    # Normalize the feature maps\n",
    "    feature_map_1 = layer[feature_map_1_id]\n",
    "    feature_map_2 = layer[feature_map_2_id]\n",
    "\n",
    "    # Compute Euclidian distance\n",
    "    ed_fm1_fm2 = torch.sqrt(torch.sum((feature_map_1-feature_map_2)**2))\n",
    "\n",
    "    # Flattening  \n",
    "    feature_map_1 = feature_map_1.flatten()\n",
    "    feature_map_2 = feature_map_2.flatten()\n",
    "\n",
    "    # Compute Cossine Distance\n",
    "    cos = nn.CosineSimilarity(dim = 0, eps=1e-6)\n",
    "    cos_fm1_fm2 = cos(feature_map_1, feature_map_2)\n",
    "    \n",
    "    # A dictionary to store the data\n",
    "    results_dict = {\n",
    "        \"feature_map_1_id\" : feature_map_1_id, \n",
    "        \"feature_map_2_id\" : feature_map_2_id,\n",
    "        \"euclidian_distance\" : ed_fm1_fm2.numpy(), \n",
    "        \"cossine_distance\" : cos_fm1_fm2.numpy()\n",
    "    }\n",
    "\n",
    "    # Convert the dict to dataframe\n",
    "    df_result = pd.DataFrame([results_dict])\n",
    "    # Concact df_result with similarity_metrics to append new row\n",
    "    similarity_metrics = pd.concat([similarity_metrics, df_result])\n",
    "\n",
    "  # Reset indexes\n",
    "  similarity_metrics.reset_index(drop = True, inplace = True)\n",
    "\n",
    "  return similarity_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmL63U77JgRI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sampler to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "EVQ7IKyJD_60",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_maps(img_idx, layer):\n",
    "  \"\"\"\n",
    "  Function that receives an image index and a ResUNet layer, send the \n",
    "  feature maps of its respective image and layer to CPU and returns the \n",
    "  feature maps.  \n",
    "  \"\"\"\n",
    "  sampler = ActivationSampler(layer)\n",
    "\n",
    "  img, label = dataset[img_idx]\n",
    "  with torch.no_grad():\n",
    "      img = img.to(device)[None]\n",
    "      model(img);\n",
    "      \n",
    "  layer_feature_maps = sampler().to('cpu')[0]\n",
    "  \n",
    "  return layer_feature_maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cehuFr_aS76y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature maps masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Y6OPzqL2Pdh_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_masking(layer_feature_maps, label, iterations_level):\n",
    "  \"\"\"\n",
    "  Apply the dilation and masking over all the feature maps of ResUNet layer. \n",
    "  The dilation uses iterations_level to define the level of iterations.  \n",
    "  \"\"\"\n",
    "  # apply dilation on label with iterations_level\n",
    "  dilated_label = scipy.ndimage.binary_dilation(label, iterations = iterations_level)\n",
    "\n",
    "  # Mask all feature maps of layer_feature_maps\n",
    "  feature_maps_masked = layer_feature_maps*dilated_label\n",
    "\n",
    "  return feature_maps_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Mdf1KxH_iBT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature maps correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yV2sLPk1b2mu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_maps_correlation(layer_1_fm, layer_2_fm, layer_1_name, layer_2_name, n_maps1, n_maps2):\n",
    "\n",
    "  \n",
    "  fm_correlation = pd.DataFrame(columns=(layer_1_name+'_fm_id', layer_2_name+'_fm_id', 'correlation'))\n",
    "\n",
    "  # Create Object to progress bar\n",
    "  prog = pyprog.ProgressBar(\" \", \"\", n_maps1)\n",
    "  # Print Task name\n",
    "  print('Computing feature maps correlation: \\n')\n",
    "  # Update Progress Bar\n",
    "  prog.update()\n",
    "\n",
    "\n",
    "  for map_idx1 in range(n_maps1):\n",
    "    layer_1_map_1d = layer_1_fm[map_idx1].flatten()\n",
    "\n",
    "    for map_idx2 in range(n_maps2):   \n",
    "      \n",
    "      layer_2_map_1d = layer_2_fm[map_idx2].flatten()\n",
    "      corr = np.corrcoef(layer_1_map_1d, layer_2_map_1d)[0][1]\n",
    "\n",
    "      fm_correlation_dict = {\n",
    "          layer_1_name+'_fm_id' : map_idx1, \n",
    "          layer_2_name+'_fm_id' : map_idx2,\n",
    "          'correlation'         : corr\n",
    "\n",
    "      }\n",
    "\n",
    "      # Convert the dict to dataframe\n",
    "      df_result = pd.DataFrame([fm_correlation_dict])\n",
    "      # Concact df_result with similarity_metrics to append new row\n",
    "      fm_correlation = pd.concat([fm_correlation, df_result])\n",
    "      \n",
    "    # Set current status\n",
    "    prog.set_stat(map_idx1 + 1)\n",
    "    # Update Progress Bar\n",
    "    prog.update()\n",
    "\n",
    "  # Make the Progress Bar final\n",
    "  prog.end()\n",
    "\n",
    "  # Reset indexes\n",
    "  fm_correlation.reset_index(drop = True, inplace = True)\n",
    "\n",
    "  return fm_correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTjnSKWXA16-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prototype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7J4d5lKqFeeB"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlearner_vessel.tar\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Load model\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mload_model_checkpoint\u001B[0;34m(path, device)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model_checkpoint\u001B[39m(path, device):\n\u001B[1;32m      2\u001B[0m   \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m  Load the model from a checkpoint given a path to file and the device which \u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m  will process the model\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m   checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m   model \u001B[38;5;241m=\u001B[39m ResUNet(num_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m) \n\u001B[1;32m      8\u001B[0m   model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_state\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:594\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    592\u001B[0m             opened_file\u001B[38;5;241m.\u001B[39mseek(orig_position)\n\u001B[1;32m    593\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(opened_file)\n\u001B[0;32m--> 594\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:853\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m    851\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mUnpickler(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m    852\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m--> 853\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:845\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m    843\u001B[0m data_type, key, location, size \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    844\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m loaded_storages:\n\u001B[0;32m--> 845\u001B[0m     \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    846\u001B[0m storage \u001B[38;5;241m=\u001B[39m loaded_storages[key]\n\u001B[1;32m    847\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m storage\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:834\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(data_type, size, key, location)\u001B[0m\n\u001B[1;32m    831\u001B[0m dtype \u001B[38;5;241m=\u001B[39m data_type(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m    833\u001B[0m storage \u001B[38;5;241m=\u001B[39m zip_file\u001B[38;5;241m.\u001B[39mget_storage_from_record(name, size, dtype)\u001B[38;5;241m.\u001B[39mstorage()\n\u001B[0;32m--> 834\u001B[0m loaded_storages[key] \u001B[38;5;241m=\u001B[39m \u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:814\u001B[0m, in \u001B[0;36m_get_restore_location.<locals>.restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrestore_location\u001B[39m(storage, location):\n\u001B[0;32m--> 814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdefault_restore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:175\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 175\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:151\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 151\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    153\u001B[0m             storage_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda, \u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/serialization.py:132\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_cuda_device\u001B[39m(location):\n\u001B[0;32m--> 132\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_device_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    136\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    137\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    138\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    139\u001B[0m                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/cuda/_utils.py:32\u001B[0m, in \u001B[0;36m_get_device_index\u001B[0;34m(device, optional, allow_cpu)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m device\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected a cuda device, but got: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(device))\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_torch_get_device_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_cpu\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/_utils.py:489\u001B[0m, in \u001B[0;36m_get_device_index\u001B[0;34m(device, optional, allow_cpu)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device_idx \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m optional:\n\u001B[0;32m--> 489\u001B[0m         device_idx \u001B[38;5;241m=\u001B[39m \u001B[43m_get_current_device_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    490\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    491\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected a torch.device with a specified index \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    492\u001B[0m                          \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mor an integer, but got:\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(device))\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/_utils.py:448\u001B[0m, in \u001B[0;36m_get_current_device_index\u001B[0;34m()\u001B[0m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_current_device_index\u001B[39m():\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;66;03m# current device index\u001B[39;00m\n\u001B[0;32m--> 448\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_device_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/inciacao_cientifica/lib/python3.9/site-packages/torch/_utils.py:440\u001B[0m, in \u001B[0;36m_get_device_attr\u001B[0;34m(get_member)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_device_attr\u001B[39m(get_member):\n\u001B[1;32m    439\u001B[0m     device_type \u001B[38;5;241m=\u001B[39m _get_available_device_type()\n\u001B[0;32m--> 440\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdevice_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    441\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m get_member(torch\u001B[38;5;241m.\u001B[39mcuda)\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# add more available device types here\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = dataset_creation('data', 'CD31(vessels)', 'labels')\n",
    "# Model path\n",
    "model_path = 'learner_vessel.tar'\n",
    "# Load model\n",
    "model = load_model_checkpoint(model_path, 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ExtractResUNetLayers class"
   ],
   "metadata": {
    "id": "5fHjEKYEN14L",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ExtractResUNetLayers:\n",
    "  \"\"\"Layers extractor class for PyTorch ResUNet. \n",
    "\n",
    "    Receives the model, the network part (encoder or decoder) and the names of the layers to be extracted\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torchtrainer.models.resunet.ResUNet\n",
    "        Directory containing the images to be read\n",
    "    network_part : string\n",
    "        A string the represents the name of ResUNet Network part. network_part = 'encoder' or 'decoder'\n",
    "    layer_names : list \n",
    "        Contains the names of layers belonging network_part. \n",
    "        e.g. If network_part == 'encoder', a possible list of layers is: ['resblock1', 'resblock2', ...]\n",
    "    \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, model:str, network_part:str, layer_names:list):\n",
    "    self.model = model\n",
    "    self.network_part = network_part\n",
    "    self.layer_names = layer_names\n",
    "\n",
    "    # Get model network part (encoder or decoder) \n",
    "    self.model_network_part = getattr(self.model, self.network_part)\n",
    "  \n",
    "  def get_number_maps(self, layer):\n",
    "    \"\"\"\n",
    "    \"\"\"   \n",
    "    # Get number of feature maps of layer\n",
    "    n_maps = layer.conv1.out_channels\n",
    "\n",
    "    return n_maps\n",
    "  \n",
    "  def get_layers(self):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    layers_dict = {\n",
    "      \"layer_name\":[], \n",
    "      \"network_part\":[],\n",
    "      \"n_maps\":[], \n",
    "      \"layer\":[], \n",
    "\n",
    "    }\n",
    "\n",
    "    for i, name in enumerate(self.layer_names):\n",
    "      # Get desired layer from model \n",
    "      layer = getattr(self.model_network_part, name)\n",
    "      n_maps = self.get_number_maps(layer)\n",
    "      \n",
    "      # Dict appending\n",
    "      layers_dict[\"layer_name\"].append(name)\n",
    "      layers_dict[\"network_part\"].append(self.network_part)      \n",
    "      layers_dict[\"n_maps\"].append(n_maps)\n",
    "      layers_dict[\"layer\"].append(layer)\n",
    "\n",
    "    return layers_dict\n"
   ],
   "metadata": {
    "id": "YrDtAHrtQUAF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650597881321,
     "user_tz": 180,
     "elapsed": 292,
     "user": {
      "displayName": "Wesley Nogueira Galvão",
      "userId": "13330399802249856427"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ExtractResUNetLayers test\n",
    "layer_name = ['resblock1', 'resblock2', 'resblock3']\n",
    "erl = ExtractResUNetLayers(model, 'encoder', layer_name)\n",
    "layers = erl.get_layers()\n"
   ],
   "metadata": {
    "id": "krQ4of5UYYan",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 40,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ExtractResUNetLayers test\u001B[39;00m\n\u001B[1;32m      2\u001B[0m layer_name \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresblock1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresblock2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresblock3\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 3\u001B[0m erl \u001B[38;5;241m=\u001B[39m \u001B[43mExtractResUNetLayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mencoder\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m layers \u001B[38;5;241m=\u001B[39m erl\u001B[38;5;241m.\u001B[39mget_layers()\n",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36mExtractResUNetLayers.__init__\u001B[0;34m(self, model, network_part, layer_names)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_names \u001B[38;5;241m=\u001B[39m layer_names\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Get model network part (encoder or decoder) \u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_network_part \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork_part\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'encoder'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ExtractResUNetMaps Class"
   ],
   "metadata": {
    "id": "HERezDnGN_Ga",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m network_part \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m img_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m----> 5\u001B[0m erl \u001B[38;5;241m=\u001B[39m ExtractResUNetLayers(\u001B[43mmodel\u001B[49m, network_part, layer_name)\n\u001B[1;32m      6\u001B[0m layers \u001B[38;5;241m=\u001B[39m erl\u001B[38;5;241m.\u001B[39mget_layers()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "layers_name = ['resblock1', 'resblock2']\n",
    "network_part = 'encoder'\n",
    "img_idx = 3\n",
    "\n",
    "erl = ExtractResUNetLayers(model, network_part, layer_name)\n",
    "layers = erl.get_layers()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "HmFeCfR4lH66",
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650597137090,
     "user_tz": 180,
     "elapsed": 12459,
     "user": {
      "displayName": "Wesley Nogueira Galvão",
      "userId": "13330399802249856427"
     }
    },
    "outputId": "389f88b0-4eaf-4fff-ab6e-4dfaf0d8660d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [44]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m network_part \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoder\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m img_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[0;32m----> 5\u001B[0m erl \u001B[38;5;241m=\u001B[39m \u001B[43mExtractResUNetLayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetwork_part\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m layers \u001B[38;5;241m=\u001B[39m erl\u001B[38;5;241m.\u001B[39mget_layers()\n\u001B[1;32m      8\u001B[0m layers_fm_list \u001B[38;5;241m=\u001B[39m get_multiple_feature_maps(img_idx, layers[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayer\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36mExtractResUNetLayers.__init__\u001B[0;34m(self, model, network_part, layer_names)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer_names \u001B[38;5;241m=\u001B[39m layer_names\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Get model network part (encoder or decoder) \u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_network_part \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetwork_part\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "\n",
    "layers_fm_list = get_multiple_feature_maps(img_idx, layers['layer'])\n",
    "\n",
    "maps_idx = [2,6,7,52]\n",
    "\n",
    "show_feature_maps(img_idx, layers_name, layers_fm_list, maps_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import timeit\n",
    "runtimes = []\n",
    "threads = [1] + [t for t in range(2, 49, 2)]\n",
    "for t in threads:\n",
    "    torch.set_num_threads(t)\n",
    "    r = timeit.timeit(setup = \"import torch; x = torch.randn(1024, 1024); y = torch.randn(1024, 1024)\", stmt=\"torch.mm(x, y)\", number=100)\n",
    "    runtimes.append(r)\n",
    "# ... plotting (threads, runtimes) ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QSyLNtWSZjte",
    "kXoS1pAmbJVZ",
    "uBpe5BDoyXJq",
    "1kGB3H2eygjn"
   ],
   "name": "05_Prototipo_biblioteca_analise_similaridade.ipynb",
   "provenance": [],
   "history_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}