{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Resunet Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSyLNtWSZjte",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11620,
     "status": "ok",
     "timestamp": 1650593813868,
     "user": {
      "displayName": "Wesley Nogueira Galv√£o",
      "userId": "13330399802249856427"
     },
     "user_tz": 180
    },
    "id": "6bed8efe",
    "outputId": "e6b96145-9790-45ff-d2cf-29f55ffc6328",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from re import split\n",
    "\n",
    "import pyprog\n",
    "\n",
    "# Initial imports and device setting\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import interpolate \n",
    "from torch.functional import F\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "# Libraries for graph\n",
    "import networkx.drawing as draw\n",
    "import networkx as nx\n",
    "\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from torchtrainer.imagedataset import ImageSegmentationDataset\n",
    "from torchtrainer import img_util\n",
    "from torchtrainer import transforms\n",
    "from torchtrainer.models.resunet import ResUNet\n",
    "from torchtrainer.module_util import ActivationSampler\n",
    "\n",
    "# Import Resunet Explorer library \n",
    "from resunetexplorer.layer_extractor import ExtractResUNetLayers\n",
    "from resunetexplorer.maps_extractor import ExtractResUNetMaps\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "# PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "use_cuda = False\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dev_info = torch.cuda.get_device_properties(device)\n",
    "    print(dev_info)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXoS1pAmbJVZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6smclHNFbVcg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_creation(root_dir_, img_dir_, label_dir_):\n",
    "  \"\"\"\n",
    "  Load the dataset given the complet path.\n",
    "  \"\"\"\n",
    "  # Dataset creation\n",
    "  def img_name_to_label(filename):\n",
    "      return filename.split('.')[0] + '.png'\n",
    "\n",
    "  root_dir = Path(root_dir_)\n",
    "  img_dir = root_dir/img_dir_\n",
    "  label_dir = root_dir/label_dir_\n",
    "\n",
    "  # Data transformations\n",
    "  imgaug_seq = iaa.Sequential([\n",
    "      iaa.CLAHE(clip_limit=6, tile_grid_size_px=12)\n",
    "  ])    \n",
    "  imgaug_seq = transforms.translate_imagaug_seq(imgaug_seq)\n",
    "  valid_transforms = [transforms.TransfToImgaug(), imgaug_seq, transforms.TransfToTensor(), \n",
    "                      transforms.TransfWhitten(67.576, 37.556)]\n",
    "\n",
    "  img_opener = partial(img_util.pil_img_opener, channel=None)\n",
    "  label_opener = partial(img_util.pil_img_opener, is_label=True)\n",
    "  dataset = ImageSegmentationDataset(img_dir, label_dir, name_to_label_map=img_name_to_label, img_opener=img_opener, \n",
    "                                    label_opener=label_opener, transforms=valid_transforms)\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-7wLMdaarzC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_checkpoint(path, device):\n",
    "  \"\"\"\n",
    "  Load the model from a checkpoint given a path to file and the device which \n",
    "  will process the model\n",
    "  \"\"\"\n",
    "  checkpoint = torch.load(path, map_location=torch.device(device))\n",
    "  model = ResUNet(num_channels=1, num_classes=2) \n",
    "  model.load_state_dict(checkpoint['model_state'])\n",
    "  model.eval()\n",
    "  model.to(device);\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTjnSKWXA16-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature maps visulization example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7J4d5lKqFeeB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = dataset_creation('data', 'CD31(vessels)', 'labels')\n",
    "# Model path\n",
    "model_path = 'learner_vessel.tar'\n",
    "# Load model\n",
    "model = load_model_checkpoint(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fHjEKYEN14L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ExtractResUNetLayers class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ExtractResUNetLayers test\n",
    "layers_paths = ['encoder.resblock1.conv1', \n",
    "                '_l4.conv1']\n",
    "erl = ExtractResUNetLayers(model, layers_paths)\n",
    "layers = erl.get_layers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network_part': ['encoder.resblock1.conv1', '_l4.conv1'],\n",
       " 'n_maps': [64, 512],\n",
       " 'layer': [Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       "  Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HERezDnGN_Ga",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ExtractResUNetMaps Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "layers_fm_list = get_multiple_feature_maps(img_idx, layers['layer'])\n",
    "\n",
    "maps_idx = [2,6,7,52]\n",
    "\n",
    "show_feature_maps(img_idx, layers_name, layers_fm_list, maps_idx)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QSyLNtWSZjte",
    "kXoS1pAmbJVZ",
    "uBpe5BDoyXJq",
    "1kGB3H2eygjn"
   ],
   "history_visible": true,
   "name": "05_Prototipo_biblioteca_analise_similaridade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
